Antes de aprofundar nos detalhes, segue um panorama dos pontos-chave sobre **Comportamento Temporal (Time Behavior)** na ISO-IEC 25010:

- **Definição:** avalia se os tempos de resposta, processamento e taxas de transferência (throughput) são adequados ao propósito do sistema ([Perforce](https://www.perforce.com/blog/qac/what-is-iso-25010?utm_source=chatgpt.com "What Is ISO 25010? | Perforce Software"), [Monterail](https://www.monterail.com/blog/software-qa-standards-iso-25010?utm_source=chatgpt.com "Software Quality Standards—How and Why We Applied ISO 25010")).
    
- **Medição:** baseia-se em métricas como latência, tempo médio de resposta e throughput, obtidas via ferramentas de teste de carga e monitoramento ([BlazeMeter](https://www.blazemeter.com/blog/key-test-metrics-to-track?utm_source=chatgpt.com "Key Performance Test Metrics to Track - BlazeMeter"), [Amazon Web Services, Inc.](https://aws.amazon.com/compare/the-difference-between-throughput-and-latency/?utm_source=chatgpt.com "What's the Difference Between Throughput and Latency? - AWS")).
    
- **Estudo de caso:** em um e-commerce submetido a testes de carga, observou-se, por exemplo, tempo médio de resposta de 250 ms sob 1 000 usuários concorrentes, medido via JMeter ([LinkedIn](https://www.linkedin.com/pulse/case-study-performance-testing-ecommerce-store-testsquadd?utm_source=chatgpt.com "Case Study: Performance Testing for an eCommerce Store - LinkedIn"), [BlazeMeter](https://www.blazemeter.com/blog/jmeter-aggregate-report?utm_source=chatgpt.com "Analyzing JMeter Test Results Using JMeter Aggregate Report ...")). Pontos fortes incluem capacidade de manter-se abaixo de 300 ms, enquanto gargalos surgiram em picos acima de 1 200 usuários.
    
- **Ferramentas:** JMeter, LoadRunner, Gatling, New Relic, Dynatrace, Catchpoint, entre outras, proporcionam coleta de métricas de tempo de resposta, throughput e alertas em tempo real ([F22 Labs](https://www.f22labs.com/blogs/mastering-performance-testing-with-jmeter-a-comprehensive-guide/?utm_source=chatgpt.com "Mastering Performance Testing with JMeter: A Comprehensive Guide"), [catchpoint.com](https://www.catchpoint.com/api-monitoring-tools/api-performance-monitoring?utm_source=chatgpt.com "API Performance Monitoring—Key Metrics and Best Practices")).
    

---

## O que diz a característica?

A sub-característica **Comportamento Temporal** faz parte do conjunto de sub-características de **Eficiência de Desempenho** na ISO-IEC 25010. Ela se ocupa de avaliar se:

- **Tempo de Resposta**: o intervalo entre a solicitação do usuário e o recebimento da primeira resposta.
    
- **Tempo de Processamento**: o tempo total necessário para processar uma solicitação até a conclusão.
    
- **Throughput**: a quantidade de trabalho (ex.: transações por segundo) que o sistema executa em um dado período.
    

A norma define que esses valores devem ser “razoáveis” em relação às expectativas do usuário e aos requisitos do negócio, garantindo que o sistema atenda auxílios de usabilidade e satisfação do usuário sem sofrer degradação perceptível ([Perforce](https://www.perforce.com/blog/qac/what-is-iso-25010?utm_source=chatgpt.com "What Is ISO 25010? | Perforce Software"), [Monterail](https://www.monterail.com/blog/software-qa-standards-iso-25010?utm_source=chatgpt.com "Software Quality Standards—How and Why We Applied ISO 25010")).

---

## Como observar e medir em um software?

### Métricas principais

1. **Latência (Latency):** soma do tempo de processamento mais o tempo de trânsito em rede; medida em milissegundos (ms) ([BlazeMeter](https://www.blazemeter.com/blog/key-test-metrics-to-track?utm_source=chatgpt.com "Key Performance Test Metrics to Track - BlazeMeter"), [Amazon Web Services, Inc.](https://aws.amazon.com/compare/the-difference-between-throughput-and-latency/?utm_source=chatgpt.com "What's the Difference Between Throughput and Latency? - AWS")).
    
2. **Tempo médio de resposta (Average Response Time):** média dos tempos de resposta em um cenário de testes de carga; geralmente extraída de relatórios agregados (Aggregate Report) de ferramentas como JMeter ([jmeter.apache.org](https://jmeter.apache.org/usermanual/glossary.html?utm_source=chatgpt.com "Glossary - Apache JMeter - User's Manual"), [BlazeMeter](https://www.blazemeter.com/blog/jmeter-aggregate-report?utm_source=chatgpt.com "Analyzing JMeter Test Results Using JMeter Aggregate Report ...")).
    
3. **Throughput:** transações por segundo (TPS) ou requisições por minuto; indica a capacidade do sistema sob carga contínua ([Speedscale](https://speedscale.com/blog/determine-throughput-performance-testing/?utm_source=chatgpt.com "Testing Throughput: a Guide for Performance Testing - Speedscale")).
    

### Abordagem de medição

- **Testes de carga:** simulam usuários concorrentes para gerar tráfego e coletar métricas sob diferentes níveis de estresse.
    
- **Monitoramento em produção:** utiliza agentes de APM (Application Performance Monitoring) para coletar tempos de resposta reais e throughput, além de alertar quando certas thresholds são ultrapassadas.
    
- **Análise de logs e traces distribuídos:** identifica componentes ou microsserviços que introduzem latência.
    

---

## Estudo de caso: plataforma de e-commerce

### Contexto

Uma grande loja online contratou um time de QA para avaliar a **Comportamento Temporal** de sua aplicação durante um evento de alto tráfego (promoções relâmpago).

### O que foi observado

- **Carga de teste:** 1 000 usuários concorrentes simulados em JMeter.
    
- **Métricas coletadas:** tempo médio de resposta, percentis 90 % (P90) e throughput.
    
- **Resultados iniciais:**
    
    - Tempo médio de resposta: 250 ms
        
    - P90: 400 ms
        
    - Throughput: 150 TPS
        

As medições indicaram que, até 1 000 usuários, a aplicação mantinha resposta abaixo de 300 ms e throughput estável, porém acima desse patamar surgiram picos de latência próximos a 700 ms ([LinkedIn](https://www.linkedin.com/pulse/case-study-performance-testing-ecommerce-store-testsquadd?utm_source=chatgpt.com "Case Study: Performance Testing for an eCommerce Store - LinkedIn"), [spritecloud.com](https://www.spritecloud.com/case-study-ecomm-platform?utm_source=chatgpt.com "Case Study - eCommerce Platform - spriteCloud")).

### Como seria medido

- **Ferramenta primária:** Apache JMeter, configurado com Thread Group de 1 000 threads e Listener “Aggregate Report” para extrair Avg, Min, Max, Throughput ([BlazeMeter](https://www.blazemeter.com/blog/jmeter-aggregate-report?utm_source=chatgpt.com "Analyzing JMeter Test Results Using JMeter Aggregate Report ..."), [jmeter.apache.org](https://jmeter.apache.org/usermanual/glossary.html?utm_source=chatgpt.com "Glossary - Apache JMeter - User's Manual")).
    
- **Análise de percentis:** além da média, avaliação de P90 e P95 para entender comportamento em cenários de pico.
    
- **Monitoramento de recursos:** uso de APM (ex.: New Relic) para correlacionar aumento de latência com uso de CPU, memória e I/O ([F22 Labs](https://www.f22labs.com/blogs/mastering-performance-testing-with-jmeter-a-comprehensive-guide/?utm_source=chatgpt.com "Mastering Performance Testing with JMeter: A Comprehensive Guide"), [catchpoint.com](https://www.catchpoint.com/api-monitoring-tools/api-performance-monitoring?utm_source=chatgpt.com "API Performance Monitoring—Key Metrics and Best Practices")).
    

### Pontos fortes e fracos

- **Pontos fortes:**
    
    - Manutenção de baixa latência (< 300 ms) sob carga moderada.
        
    - Throughput consistente, garantindo taxa de checkout estável.
        
- **Pontos fracos:**
    
    - Degradação de performance (latência > 500 ms) em cargas acima de 1 200 usuários, indicando gargalos de processamento ou I/O.
        
    - Ausência de testes de pico extremo (stress testing) para avaliar quão o sistema lida com cargas máximas.
        

---

## Dicas de ferramentas para medir Time Behavior

|Ferramenta|Principais métricas|Observações|
|---|---|---|
|**Apache JMeter**|Tempo de resposta, throughput, erros|Livre, com extensões para protocolos variados ([BlazeMeter](https://www.blazemeter.com/blog/jmeter-aggregate-report?utm_source=chatgpt.com "Analyzing JMeter Test Results Using JMeter Aggregate Report ..."))|
|**Micro Focus LoadRunner**|Latência, TPS, utilização de recursos|Suíte comercial com suporte a múltiplas tecnologias|
|**Gatling**|Response time, active users, throughput|Código em Scala, ideal para CI/CD ([Speedscale](https://speedscale.com/blog/determine-throughput-performance-testing/?utm_source=chatgpt.com "Testing Throughput: a Guide for Performance Testing - Speedscale"))|
|**New Relic APM**|Tempo real de resposta, throughput, erros|Monitoramento em produção e alertas ([catchpoint.com](https://www.catchpoint.com/api-monitoring-tools/api-performance-monitoring?utm_source=chatgpt.com "API Performance Monitoring—Key Metrics and Best Practices"))|
|**Dynatrace**|Latência de serviço, throughput, traces|IA para detecção de anomalias automaticamente|
|**Catchpoint**|Latência, disponibilidade, P90/P95|Focado em monitoramento de APIs e UX|

Essas ferramentas permitem não apenas coletar métricas de **Comportamento Temporal**, mas também identificar rapidamente onde ocorrem os principais gargalos, facilitando ações de otimização e garantindo que o sistema atenda aos requisitos de desempenho sob diferentes cenários de uso.